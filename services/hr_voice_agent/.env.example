# --- LLM (question generation) ---
# Provider options: openai | groq
LLM_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4.1-mini

# Groq (OpenAI-compatible endpoint)
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# --- Embeddings (for Pinecone retrieval) ---
# Options: openai | postgres | none
#
# Recommended (no OpenAI required):
# - Set EMBEDDING_PROVIDER=postgres
# - Ensure your Postgres has rows in the `embeddings` table (pgvector)
# - Run: python -m hr_voice_agent.tools.sync_pinecone
EMBEDDING_PROVIDER=openai
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# --- Postgres ---
POSTGRES_DSN=postgresql://user:password@host:5432/engineering_intelligence

# --- Neo4j ---
NEO4J_URI=
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j

# --- Pinecone ---
PINECONE_API_KEY=
# IMPORTANT: must be an index that exists in YOUR Pinecone project for this API key.
# (Example from our current key's visible indexes: policy-index)
PINECONE_INDEX=policy-index
PINECONE_NAMESPACE_DEVELOPER_PROFILES=developer_profiles
PINECONE_NAMESPACE_PROJECT_DOCS=project_docs

# --- Agent behavior ---
DEFAULT_TOP_K=8
MAX_QUESTIONS=8

# --- TTS (free/local) ---
# Options: macos_say | piper | none
TTS_BACKEND=macos_say

# Piper (free open-source model). Configure these only if using TTS_BACKEND=piper
PIPER_BINARY=piper
PIPER_MODEL_PATH=
PIPER_SPEAKER_ID=0
